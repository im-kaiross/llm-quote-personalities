# LLM "personalities" - a bored student's first "paper"
>1: i'll use human pronouns because it's hard not to anthropomorphize them and the used pron's are what i felt like calling them, | 2: fuck grammar and formality, i write essays every other week, so i get to do what i want with my own writing


# what do i mean by "personalities" for LLMs? and why did i do this?
to sum it up, i noticed when interacting with all sorts of LLMs they all acted a little differently and had their own "personalities", now i assume this is a consequence of their architecture, training data, system prompt, user prompt, and jsut the temperature value but it was still consistent per model so i looked into it a bit and here we are


# let's get started
>note: i dont know formatting for shit so i'll jsut use basic ascii stuff but i'll try to make it look ok
we're gonna start with the smaller models first, i used tinyllama, smollm, qwen3, gemma3, granite3.2, mistral, llama3.1, llava1.5, and 2 llama/qwen distills of deepseek-r1
the used settings and stuff are in, you guessed it, !-used-settings

# smollm and tinyllama (the idiots)
tinyllama; just stupid, not much personality with this one
>tinyllama wrote about some guy named alex from a 1st POV, sounded like an english class assignment response and 

smollm; also too small and stupid to have a consistent personality
>smollm was not much better but impressive for a gpt2 size model, yapped about digital art and the sort

